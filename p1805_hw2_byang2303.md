Homework 2
================
Bin Yang

    library(tidyverse)

    ## â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.0 â”€â”€

    ## âœ“ ggplot2 3.3.2     âœ“ purrr   0.3.4
    ## âœ“ tibble  3.0.3     âœ“ dplyr   1.0.2
    ## âœ“ tidyr   1.1.2     âœ“ stringr 1.4.0
    ## âœ“ readr   1.3.1     âœ“ forcats 0.5.0

    ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

    library(readxl)

Problem 1
---------

Read the Mr.Â Trashwheel dataset.

    trashwheel_df <- 
      read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                sheet = "Mr. Trash Wheel", 
                range = cell_cols("A:N")) %>% 
      janitor::clean_names() %>% 
      drop_na(dumpster) %>% 
      mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
      )

Read precipitation data for 2018 and 2017.

    precip_2018 <- 
      read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
      ) %>% 
      janitor::clean_names() %>% 
      drop_na(month) %>% 
      mutate(year = 2018) %>% 
      relocate(year)

    precip_2017 <- 
      read_excel(
        "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
      ) %>% 
      janitor::clean_names() %>% 
      drop_na(month) %>% 
      mutate(year = 2017) %>% 
      relocate(year)

Now combine annual precipitation.

    month_df <-  
      tibble(
        month = 1:12,
        month_name = month.name
      )

    precip_df <- 
      bind_rows(precip_2018, precip_2017)

    left_join(precip_df, month_df, by = "month") 

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # â€¦ with 14 more rows

This is dataset contains information from Mr.Â Trashwheel trash collector
in Baltimore, MD. As trash enters the inner harbor, the trashweel
collects that trash, and stores it in a dumpster. The dataset contains
information on year, month, and trash collected, include some specific
kinds of trash. There are a total of 344 rows in our final dataset.
Additional data sheets include month precipitation data.

Problem 2
---------

Read the NYC Transit Subway Entrance And Exit Data

    nyc_subway_df <- 
      read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
               skip = 1) %>% 
      janitor::clean_names() %>% 
      select(line: entry, vending, ada) %>% 
      mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE ))

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

    ## Warning: 4 parsing failures.
    ##  row                                                                                                                                           col   expected        actual                                                   file
    ## 1869 _WebResourceData_WebResourceMIMEType_WebResourceTextEncodingName^WebResourceURL_WebResourceFrameNameO            embedded null './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv'
    ## 1869 NA                                                                                                                                            32 columns 1 columns     './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv'
    ## 1870 _WebResourceData_WebResourceMIMEType_WebResourceTextEncodingName^WebResourceURL_WebResourceFrameNameO            embedded null './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv'
    ## 1870 NA                                                                                                                                            32 columns 1 columns     './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv'

This data set contains information related to subway station in NYC,
including line, station, name, station latitude / longitude, routes
served, entry, vending, entrance type, exit, ADA compliance, staffing,
staff hours, and entrance location. As a start, I cleaned the variables
names, selected interested variables and changed the â€œentryâ€ from
character to logical type. After these steps, the resulting dataset has
1870 rows, and 19 columns. The data however is not yet tidy. For next
steps, I want to merge the route variables into one single column.

The number of distinct stations.

    nyc_subway_df %>% 
      distinct(line, station_name) %>% 
      nrow()

    ## [1] 466

The number of ADA compliant stations.

    nyc_subway_df %>% 
      filter(ada == TRUE) %>% 
      nrow()

    ## [1] 468

The proportion of station entrances without vending allow entrance.

    nyc_subway_df %>% 
      filter(entry == TRUE, vending == "NO") %>% 
      nrow() / nrow(nyc_subway_df)

    ## [1] 0.0368984

Reformat the dataset.

    nyc_subway_df <- 
      nyc_subway_df %>% 
      mutate(across(contains("route"), as.character))

    nyc_subway_tidy_df <- 
      pivot_longer(
        nyc_subway_df,
        route1:route11,
        names_to = "route_number",
        names_prefix = "route",
        values_to = "route_name"
      )

The number of distinct stations.

    nyc_subway_tidy_df %>% 
      filter(route_name == "A") %>% 
      distinct(line, station_name) %>% 
      nrow()

    ## [1] 60

The number of ada compliant stations that serve A train.

    nyc_subway_tidy_df %>% 
      filter(route_name == "A", ada == TRUE) %>% 
      distinct(line, station_name) %>% 
      nrow()

    ## [1] 17

Problem 3
---------

Read in and tidy pol\_months dataset.

    pols_months_df <- 
      read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
      separate(mon, sep = "-", into = c("year", "month", "day")) %>% 
      mutate(month = as.numeric(month)) %>% 
      mutate(month = month.abb[month]) %>% 
      pivot_longer(
        cols = starts_with("prez"),
        names_to = "president",
        values_to = "result"
      ) %>% 
      mutate(president = recode(president, "prez_dem" = "dem", "prez_gop" = "gop")) %>% 
      filter(result == 1) %>% 
      select(-day, -result)

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Read in and tidy snp dataset.

    snp_df <- 
      read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
      separate(date, sep = "/", into = c("month", "day", "year")) %>% 
      mutate(month = as.numeric(month)) %>% 
      mutate(month = month.abb[month]) %>% 
      select(-day) %>% 
      relocate(year)

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read in and tidy unemployment dataset.

    uneply_df <- 
      read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
        pivot_longer(
        cols = Jan:Dec,
        names_to = "month",
        values_to = "unemployment"
        ) %>% 
      rename(year = Year) %>% 
      mutate(year = as.character(year)) 

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merge snp and pols.

    final_df  <- 
      left_join(pols_months_df, snp_df, by = c("year", "month"))

    final_df <- 
      left_join(final_df, uneply_df, by =  c("year", "month"))

The â€œpols-monthâ€ dataset contains 822 observations of 9 variables
regarding the information of politicians, including president, number of
governors, representatives, and senators of each party from 1947 to
2015; The â€œsnpâ€ dataset contains 787 observations of 2 variables
regarding the information of Standard & Poorâ€™s stock market index (S&P)
closing value from 1950 to 2015; The dataset â€œunemploymentâ€ contains 68
observations of 13 variables regarding the information of unemployment
rate from 1948 to 2015.

The merged dataset contains 817 observations and 11 variables. The final
dataset contains information regarding number of politicians of each
party, S&P closing values, and unemployment rate from 1947 to 2015.
